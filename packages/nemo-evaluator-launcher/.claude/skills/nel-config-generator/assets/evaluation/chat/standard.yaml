# Standard LLM Benchmarks for chat models (chat endpoint)
# Note: gpqa_diamond is in math_reasoning.yaml to avoid duplicates when combining benchmarks
evaluation:
  tasks:
    - name: lm-evaluation-harness.ifeval
    - name: lm-evaluation-harness.gsm8k_cot_instruct # chat version with CoT
    - name: nemo_skills.ns_mmlu_pro # chat version
