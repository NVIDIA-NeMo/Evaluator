# SPDX-FileCopyrightText: Copyright (c) 2025, NVIDIA CORPORATION. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# How to use: copy this file locally into a directory, say `examples`, and run
# Run this config with `nemo-evaluator-launcher run --config-dir examples --config-name lepton_none_llama_3_1_8b_instruct`.

# This example shows how to use Lepton as an execution platform with an EXISTING endpoint.
# Execution flow:
# 1. Use the pre-deployed endpoint (no deployment step)
# 2. Run evaluation tasks as parallel Lepton jobs that connect to the existing endpoint
# 3. No cleanup needed for the endpoint (since we didn't create it)

# Prerequisites:
# 1. Configure your Lepton credentials: lep login
# 2. Have HuggingFace token configured for model access (UI/settings/secrets, Hugging Face)
# 3. Have ENDPOINT_API_KEY configured for the endpoint (UI/settings/secrets, Custom Secret)
# 4. Have an existing endpoint already deployed (provided in target.api_endpoint.url)
# 5. Configure storage paths in UI/Utilities/Storage and update the paths in this config

# Monitoring:
# Once the evaluation starts, you can monitor it in the Lepton UI:
# - Evaluation jobs: UI/Batch Jobs

name: lepton_none_llama_3_1_8b_instruct

defaults:
  - execution: lepton/default
  - deployment: none
  - _self_

# =============================================================================
# EXECUTION CONFIGURATION
# =============================================================================
execution:
  output_dir: lepton_none_llama_3_1_8b_results

  # Optional: Override evaluation task execution settings
  evaluation_tasks:
    # resource_shape: "gpu.small"  # Override default CPU with GPU for tasks (Optional)
    timeout: 3600  # Override default 3600 timeout (this is how long we wait for the endpoint to be ready)

  lepton_platform:
    tasks:
      api_tokens:
        - value_from:
            token_name_ref: "ENDPOINT_API_KEY"

      env_vars:
        HF_TOKEN:
          value_from:
            # TODO: the name of a HF secret created via UI/settings/secrets
            secret_name_ref: "HUGGING_FACE_HUB_TOKEN"
        API_KEY:
          value_from:
            # TODO: the name of a secret created via UI/settings/secrets (custom secret), API key for your lepton deployed endpoint
            secret_name_ref: "ENDPOINT_API_KEY"

      # Node group for evaluation tasks
      node_group: "nv-int-multiteam-nebius-h200-01"
      # Storage mounts for task execution
      mounts:
        # Main workspace mount
        - from: "node-nfs:lepton-shared-fs"
          path: "/EU-Model-Builder-SAs/user_homes/${oc.env:USER}/nemo-evaluator-launcher-workspace" # TODO: set it to your lepton storage path (see UI/Utilities/Storage)
          mount_path: "/workspace"

      # Image pull secrets for task containers
      image_pull_secrets:
        - "lepton-nvidia"

# =============================================================================
# TARGET ENDPOINT CONFIGURATION (for deployment: none)
# =============================================================================
target:
  api_endpoint:
    model_id: meta/llama-3.1-8b-instruct
    url: https://xfre17eu-nim-gpqa-d-2-f110e0.xenon.lepton.run/v1/chat/completions
    api_key_name: API_KEY # API Key with access to build.nvidia.com
    # Note: For Lepton endpoints, authentication is typically handled via the platform
    # If needed, you can add api_key_name for external endpoints

# =============================================================================
# EVALUATION CONFIGURATION
# =============================================================================
evaluation:
  # Evaluation tasks to run
  tasks:
    - name: ifeval
