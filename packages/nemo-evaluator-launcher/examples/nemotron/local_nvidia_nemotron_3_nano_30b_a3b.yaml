# SPDX-FileCopyrightText: Copyright (c) 2025, NVIDIA CORPORATION. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

defaults:
  - execution: local
  - deployment: none
  - _self_

execution:
  output_dir: ./results_nvidia_nemotron_3_nano_30b_a3b
  mounts:
    evaluation:
      ./hf_cache: /root/.cache/huggingface
  env_vars:
    evaluation: {}

target:
  api_endpoint:
    model_id: nvidia/nemotron-3-nano-30b-a3b
    url: https://integrate.api.nvidia.com/v1/chat/completions
    api_key_name: NGC_API_KEY # API Key with access to build.nvidia.com

evaluation:
  env_vars:
    HF_TOKEN: HF_TOKEN
    JUDGE_API_KEY: JUDGE_API_KEY # API Key with access to gpt-4o for HLE
    HF_HOME: HF_HOME
  nemo_evaluator_config:
    config:
      params:
        max_new_tokens: 131072
        temperature: 0.99999
        top_p: 0.99999
        parallelism: 1
        request_timeout: 3600
        max_retries: 10
        extra:
          tokenizer: NVIDIA-Nemotron-Nano-3-30B-A3B-BF16
          tokenizer_backend: huggingface
    target:
      api_endpoint:
        adapter_config:
          use_caching: true
          tracking_requests_stats: true
          log_failed_requests: true
          use_request_logging: true
          max_logged_requests: 10
          use_response_logging: true
          max_logged_responses: 10
  tasks:
  - name: ns_ifbench
    nemo_evaluator_config:
      config:
        params:
          extra:
            num_repeats: 8
  - name: ns_bfcl_v3
    nemo_evaluator_config:
      config:
        params:
          temperature: 0.6
          top_p: 0.95
          extra:
            num_repeats: 1
            args: ++use_client_parsing=False
      target:
        api_endpoint:
          adapter_config:
            use_caching: false
  - name: ns_bfcl_v4
    nemo_evaluator_config:
      config:
        params:
          max_new_tokens: 8192
          temperature: 0.6
          top_p: 0.95
          extra:
            num_repeats: 1
            args: ++use_client_parsing=False
  - name: ns_livecodebench
    nemo_evaluator_config:
      config:
        params:
          extra:
            num_repeats: 8
            dataset_split: test_v5_2407_2412
  - name: ns_mmlu_pro
    nemo_evaluator_config:
      config:
        params:
          extra:
            num_repeats: 1
            args: "++prompt_config=eval/aai/mcq-10choices-boxed"
  - name: ns_gpqa
    nemo_evaluator_config:
      config:
        params:
          extra:
            num_repeats: 8
            args: "++prompt_config=eval/aai/mcq-4choices"
  - name: ns_scicode
    nemo_evaluator_config:
      config:
        params:
          extra:
            num_repeats: 8
  - name: ns_hle
    nemo_evaluator_config:
      config:
        params:
          extra:
            num_repeats: 1
            judge_support: true
            judge:
              parallelism: 16
              model_id: openai/gpt-4o
              url: ??? # Set your OpenAI-compatible API URL for the judge model
              api_key: JUDGE_API_KEY
  - name: ns_aime2025
    nemo_evaluator_config:
      config:
        params:
          extra:
            num_repeats: 64
            args: '++prompt_config="/nemo_run/code/eval_factory_prompts/math-oai.yaml"'
  - name: ns_mmlu_prox
    nemo_evaluator_config:
      config:
        params:
          extra:
            num_repeats: 1
  - name: ns_wmt24pp
  - name: tau2_bench_telecom
    env_vars:
      JUDGE_API_KEY: NGC_API_KEY
      USER_API_KEY: NGC_API_KEY
    nemo_evaluator_config:
      config:
        params:
          temperature: 0.6
          top_p: 0.95
          extra:
            n_samples: 8
            skip_failed_samples: true
            cache:
              enabled: true
              cache_dir: /results/native_cache
  - name: ruler-128k-chat
    nemo_evaluator_config:
      config:
        params:
          limit_samples: 100
          parallelism: 1
          temperature: 0.00001
          top_p: 0.99
          extra:
            tokenizer: nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16
            tokenizer_backend: hf
      target:
        api_endpoint:
          adapter_config:
            use_reasoning: false
            params_to_add: {"chat_template_kwargs": {"enable_thinking": false}, "skip_special_tokens": false}
  - name: ruler-64k-chat
    nemo_evaluator_config:
      config:
        params:
          limit_samples: 100
          parallelism: 1
          temperature: 0.00001
          top_p: 0.99
          extra:
            tokenizer: nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16
            tokenizer_backend: hf
      target:
        api_endpoint:
          adapter_config:
            use_reasoning: false
            params_to_add: {"chat_template_kwargs": {"enable_thinking": false}, "skip_special_tokens": false}
  - name: aa_lcr
    env_vars:
      JUDGE_API_KEY: NGC_API_KEY
    nemo_evaluator_config:
      config:
        params:
          temperature: 0.99999
          top_p: 0.99999
          extra:
            n_samples: 8
