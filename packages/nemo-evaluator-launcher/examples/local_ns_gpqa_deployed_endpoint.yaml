# SPDX-FileCopyrightText: Copyright (c) 2025, NVIDIA CORPORATION. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Example: Running ns_gpqa benchmark against an already deployed vLLM endpoint
#
# How to use:
#
# 1. Ensure your vLLM endpoint is running and accessible at x.x.x.x:8035
# 2. Set HF_TOKEN environment variable: export HF_TOKEN=your_huggingface_token
# 3. (Optional) Comment out limit_samples to run on full dataset
# 4. Run: nemo-evaluator-launcher run --config local_ns_gpqa_deployed_endpoint.yaml
#
# ⚠️  WARNING:
#     Always run full evaluations (without limit_samples) for actual benchmark results.
#     Using a subset of samples is solely for testing configuration and setup.
#     Results from such test runs should NEVER be used to compare models or
#     report benchmark performance.

defaults:
  - execution: local
  - deployment: none  # No deployment - using already running endpoint
  - _self_

execution:
  output_dir: results/

# Target the already deployed vLLM endpoint
target:
  api_endpoint:
    type: chat  # vLLM typically uses chat endpoint
    model_id: nvidia/nemotron-3-nano-30b-a3b  # Model identifier
    url: https://integrate.api.nvidia.com/v1/chat/completions
    api_key_name: NGC_API_KEY
    # url: http://x.x.x.x:8035/v1/chat/completions  # Your deployed endpoint
    # api_key_name: API_KEY_VAR  # Uncomment if your endpoint requires authentication

# Evaluation configuration
evaluation:
  # Environment variables needed for the evaluation
  env_vars:
    HF_TOKEN: HF_TOKEN  # Environment variable name containing your HuggingFace token
  
  # Global config settings that apply to all tasks
  nemo_evaluator_config:
    config:
      params:
        temperature: 1.0  # Deterministic for reproducibility
        top_p: 1.0
        max_new_tokens: 131072  # Allow long responses for reasoning
        request_timeout: 3600  # 10 min timeout per request
        parallelism: 1  # 1 parallel requests (adjust based on endpoint capacity)
        # limit_samples: 10  # TEST ONLY: Remove this line for full benchmark
        
  tasks:
    - name: ns_gpqa
      # ns_gpqa is GPQA Diamond benchmark
      # Requires HF_TOKEN for dataset access
      nemo_evaluator_config:
      config:
        params:
          extra:
            num_repeats: 8 # 1 for quick testing, set to 8 for full reproduction
            args: "++prompt_config=eval/aai/mcq-4choices"

