# SPDX-FileCopyrightText: Copyright (c) 2025, NVIDIA CORPORATION. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# How to use:
#
# 1. copy this file locally or clone the repository, and run
# 2. run `nemo-evaluator-launcher run --config path/to/local_basic.yaml`
#
# This is a TEST CONFIGURATION that limits all benchmarks to use only 10 samples total.
# This allows you to test your setup end-to-end quickly without running full evaluations.
#
# ⚠️  WARNING: Results from this test run should NEVER be used to compare models or
#     report benchmark performance. This is solely for testing configuration and setup.
#     Always run full evaluations (without limit_samples) for actual benchmark results.

defaults:
  - execution: local
  - deployment: none
  - _self_

execution:
  output_dir: nel-results

target:
  api_endpoint:
    # see https://build.nvidia.com/microsoft/phi-4-mini-instruct for endpoint details
    model_id: microsoft/phi-4-mini-instruct
    url: https://integrate.api.nvidia.com/v1/chat/completions
    api_key_name: NGC_API_KEY # API Key with access to build.nvidia.com

# specify the benchmarks to evaluate
evaluation:
  nemo_evaluator_config: # global config settings that apply to all tasks
    config:
      params:
        request_timeout: 3600 # timeout for API requests in seconds
        parallelism: 1 # number of parallel requests
  tasks:
    - name: AA_math_test_500 # use the default benchmark configuration
      nemo_evaluator_config: # task-specific configuration for mbpp
        config:
          extra:
            n_samples: 3
            judge:
              api_key: JUDGE_API_KEY
              model: meta/llama-3.3-70b-instruct
              url: https://integrate.api.nvidia.com/v1/chat/completions
              backend: generic
              timeout: 600
              max_retries: 25
              temperature: 0.0
              top_p: 0.0001
              max_tokens: 512
      env_vars:
        JUDGE_API_KEY: NGC_API_KEY
    - name: mbpp
      nemo_evaluator_config: # task-specific configuration for mbpp
        config:
          params:
            temperature: 0.2 # sampling temperature
            top_p: 0.95 # nucleus sampling parameter
            max_new_tokens: 2048 # maximum tokens to generate
            extra:
              n_samples: 5 # sample 5 predictions per prompt
