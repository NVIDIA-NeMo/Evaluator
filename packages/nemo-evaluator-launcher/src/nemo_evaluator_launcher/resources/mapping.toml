# Workflow diagram:
# mapping.toml
# (container = "....")
# (# container-digest:sha256:....)              <---- CI: check digests are relevant
#
#    |
#    |
#    v
# scripts/load_framework_definitions.py
# (updates the toml
#  AND
# creates the resources/all_tasks_irs,
# records TOML checksum)                        <---- pre-commit guard: checks TOML checksum
#    |          \
#    |           \
#    |            ------------------->    make docs-build
#    |                                  (builds docs on the fly)
#    v
# scripts/update_readme.py
# (updates README, records checksum)           <----- pre-commit guard: checks TOML checksum
#

[lm-evaluation-harness]
container = "nvcr.io/nvidia/eval-factory/lm-evaluation-harness:25.11"
# container-digest:sha256:e14fe5dfef7b4a3d4b307dc8e23381ac342516a43f822f54159555d574e9b5d7

[lm-evaluation-harness.tasks.chat.ifeval]
required_env_vars = []

[lm-evaluation-harness.tasks.chat.mmlu_prox]
required_env_vars = []

[lm-evaluation-harness.tasks.completions.mmlu]
required_env_vars = []

[lm-evaluation-harness.tasks.completions.mmlu_pro]

[lm-evaluation-harness.tasks.completions.global_mmlu]
[lm-evaluation-harness.tasks.completions.global_mmlu_ar]
[lm-evaluation-harness.tasks.completions.global_mmlu_bn]
[lm-evaluation-harness.tasks.completions.global_mmlu_de]
[lm-evaluation-harness.tasks.completions.global_mmlu_en]
[lm-evaluation-harness.tasks.completions.global_mmlu_es]
[lm-evaluation-harness.tasks.completions.global_mmlu_fr]
[lm-evaluation-harness.tasks.completions.global_mmlu_hi]
[lm-evaluation-harness.tasks.completions.global_mmlu_id]
[lm-evaluation-harness.tasks.completions.global_mmlu_it]
[lm-evaluation-harness.tasks.completions.global_mmlu_ja]
[lm-evaluation-harness.tasks.completions.global_mmlu_ko]
[lm-evaluation-harness.tasks.completions.global_mmlu_pt]
[lm-evaluation-harness.tasks.completions.global_mmlu_sw]
[lm-evaluation-harness.tasks.completions.global_mmlu_yo]
[lm-evaluation-harness.tasks.completions.global_mmlu_zh]

[lm-evaluation-harness.tasks.completions.global_mmlu_full]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_am]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_ar]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_bn]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_cs]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_de]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_el]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_en]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_es]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_fa]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_fil]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_fr]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_ha]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_he]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_hi]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_id]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_ig]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_it]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_ja]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_ko]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_ky]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_lt]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_mg]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_ms]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_ne]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_nl]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_ny]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_pl]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_pt]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_ro]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_ru]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_si]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_sn]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_so]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_sr]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_sv]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_sw]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_te]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_tr]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_uk]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_vi]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_yo]
[lm-evaluation-harness.tasks.completions.global_mmlu_full_zh]
[lm-evaluation-harness.tasks.completions.mmlu_logits]

[lm-evaluation-harness.tasks.chat.mmlu_instruct]

[lm-evaluation-harness.tasks.chat.mmlu_redux_instruct]

[lm-evaluation-harness.tasks.chat.mmlu_cot_0_shot_chat]

[lm-evaluation-harness.tasks.completions.gsm8k]
required_env_vars = []

[lm-evaluation-harness.tasks.chat.gsm8k_cot_instruct]
required_env_vars = []

[lm-evaluation-harness.tasks.chat.gsm8k_cot_llama]
required_env_vars = []

[lm-evaluation-harness.tasks.chat.mgsm_cot]

[lm-evaluation-harness.tasks.chat.gpqa_diamond_cot]

[lm-evaluation-harness.tasks.completions.winogrande]

[lm-evaluation-harness.tasks.completions.hellaswag]
[lm-evaluation-harness.tasks.completions.hellaswag_multilingual]

[lm-evaluation-harness.tasks.completions.commonsense_qa]

[lm-evaluation-harness.tasks.completions.openbookqa]

[lm-evaluation-harness.tasks.completions.piqa]

[lm-evaluation-harness.tasks.completions.adlr_race]

[lm-evaluation-harness.tasks.completions.social_iqa]

[lm-evaluation-harness.tasks.completions.adlr_agieval_en_cot]
[lm-evaluation-harness.tasks.completions.adlr_arc_challenge_llama_25_shot]
[lm-evaluation-harness.tasks.completions.adlr_gpqa_diamond_cot_5_shot]
[lm-evaluation-harness.tasks.completions.adlr_gsm8k_cot_8_shot]
[lm-evaluation-harness.tasks.completions.adlr_truthfulqa_mc2]
[lm-evaluation-harness.tasks.completions.adlr_humaneval_greedy]
[lm-evaluation-harness.tasks.completions.adlr_humaneval_sampled]
[lm-evaluation-harness.tasks.completions.adlr_minerva_math_nemo]
[lm-evaluation-harness.tasks.completions.adlr_arc_challenge_llama]
[lm-evaluation-harness.tasks.completions.adlr_math_500_4_shot_sampled]
[lm-evaluation-harness.tasks.completions.adlr_mmlu_pro_5_shot_base]
[lm-evaluation-harness.tasks.completions.adlr_mmlu]
[lm-evaluation-harness.tasks.completions.adlr_mbpp_sanitized_3_shot_greedy]
[lm-evaluation-harness.tasks.completions.adlr_minerva_math_nemo_4_shot]
[lm-evaluation-harness.tasks.completions.adlr_mbpp_sanitized_3_shot_sampled]
[lm-evaluation-harness.tasks.completions.adlr_mbppplus_greedy_sanitized]
[lm-evaluation-harness.tasks.completions.adlr_humanevalplus_greedy]
[lm-evaluation-harness.tasks.completions.adlr_mgsm_native_cot_8_shot]
[lm-evaluation-harness.tasks.chat.adlr_gsm8k_fewshot_cot]
[lm-evaluation-harness.tasks.completions.adlr_commonsense_qa_7_shot]
[lm-evaluation-harness.tasks.completions.adlr_winogrande_5_shot]
[lm-evaluation-harness.tasks.completions.adlr_global_mmlu_lite_5_shot]
required_env_vars = []

[lm-evaluation-harness.tasks.completions.arc_multilingual]


###############################################################################
# NOTE(agronskiy): checked parity
[mtbench]
container = "nvcr.io/nvidia/eval-factory/mtbench:25.11"
# container-digest:sha256:057cec7f1928b6bf84943f97ee73c184a90497982796878ed9d3945cf7cf2463

[mtbench.tasks.chat.mtbench]

[mtbench.tasks.chat.mtbench-cor1]


###############################################################################
# NOTE(agronskiy): checked parity
[ifbench]
container = "nvcr.io/nvidia/eval-factory/ifbench:25.11"
# container-digest:sha256:e116972dc8ad4b0cfc6bc8fa54a8eaa232c453a69cb1cbe3b4c3b674d68a14f9

[ifbench.tasks.chat.ifbench]
required_env_vars = []


###############################################################################
[simple_evals]
container = "nvcr.io/nvidia/eval-factory/simple-evals:25.11"
# container-digest:sha256:b094b89f5a7258820ca23ef7020e5b1484a9b27f8c5cd9636d0479c049f0ba1d

[simple_evals.tasks.chat.gpqa_diamond]
required_env_vars = ["HF_TOKEN"]

[simple_evals.tasks.chat.gpqa_diamond_aa_v2]
required_env_vars = ["HF_TOKEN"]

[simple_evals.tasks.chat.gpqa_diamond_aa_v2_llama_4]
required_env_vars = ["HF_TOKEN"]

[simple_evals.tasks.chat.gpqa_diamond_nemo]
required_env_vars = ["HF_TOKEN"]

[simple_evals.tasks.chat.AA_math_test_500]
required_env_vars = ["JUDGE_API_KEY"]

[simple_evals.tasks.chat.math_test_500_nemo]
required_env_vars = []

[simple_evals.tasks.chat.aime_2024_nemo]
required_env_vars = []

[simple_evals.tasks.chat.AA_AIME_2024]
required_env_vars = ["JUDGE_API_KEY"]

[simple_evals.tasks.chat.aime_2025_nemo]
required_env_vars = []

[simple_evals.tasks.chat.AIME_2025]
required_env_vars = ["JUDGE_API_KEY"]

[simple_evals.tasks.chat.humaneval]
required_env_vars = []

[simple_evals.tasks.chat.mgsm]
required_env_vars = []

[simple_evals.tasks.chat.mmlu_pro]
required_env_vars = []

[simple_evals.tasks.chat.mmlu]
required_env_vars = []

[simple_evals.tasks.chat.mmlu_llama_4]
required_env_vars = []

[simple_evals.tasks.chat.mmlu_pro_llama_4]
required_env_vars = []

[simple_evals.tasks.chat.mmlu_ar-lite]
[simple_evals.tasks.chat.mmlu_bn-lite]
[simple_evals.tasks.chat.mmlu_de-lite]
[simple_evals.tasks.chat.mmlu_en-lite]
[simple_evals.tasks.chat.mmlu_es-lite]
[simple_evals.tasks.chat.mmlu_fr-lite]
[simple_evals.tasks.chat.mmlu_hi-lite]
[simple_evals.tasks.chat.mmlu_id-lite]
[simple_evals.tasks.chat.mmlu_it-lite]
[simple_evals.tasks.chat.mmlu_ja-lite]
[simple_evals.tasks.chat.mmlu_ko-lite]
[simple_evals.tasks.chat.mmlu_my-lite]
[simple_evals.tasks.chat.mmlu_pt-lite]
[simple_evals.tasks.chat.mmlu_sw-lite]
[simple_evals.tasks.chat.mmlu_yo-lite]
[simple_evals.tasks.chat.mmlu_zh-lite]


###############################################################################
# NOTE(agronskiy): checked parity
[bigcode-evaluation-harness]
container = "nvcr.io/nvidia/eval-factory/bigcode-evaluation-harness:25.11"
# container-digest:sha256:fc34efe95cb18377b697a6e9a87ae8706dba37a1c7f690a58d22c52bfacf23d1

[bigcode-evaluation-harness.tasks.chat.mbpp]
required_env_vars = []

[bigcode-evaluation-harness.tasks.chat.mbppplus]

[bigcode-evaluation-harness.tasks.chat.mbppplus_nemo]
required_env_vars = []

[bigcode-evaluation-harness.tasks.completions.humaneval]
required_env_vars = []

[bigcode-evaluation-harness.tasks.chat.humaneval_instruct]


###############################################################################
[livecodebench]
container = "nvcr.io/nvidia/eval-factory/livecodebench:25.11"
# container-digest:sha256:2aa133755bb408bd94f931c5797a46e0fa80ea3161a46caefd1649aa567c8b66

[livecodebench.tasks.chat.livecodebench_0724_0125]
required_env_vars = []

[livecodebench.tasks.chat.livecodebench_0824_0225]
required_env_vars = []


###############################################################################
[scicode]
container = "nvcr.io/nvidia/eval-factory/scicode:25.11"
# container-digest:sha256:0b1aeb52d2231ded3d3a005333997b95981c01c64db101ca2fe35695e8b532bb

[scicode.tasks.chat.scicode_aa_v2]
required_env_vars = []


###############################################################################
[hle]
container = "nvcr.io/nvidia/eval-factory/hle:25.11"
# container-digest:sha256:98117c3a5c21bf61a68eb7cf7c4e4881a18b9da89325f51d87110e9273f53a58

[hle.tasks.chat.hle]
required_env_vars = ["HF_TOKEN", "OPENAI_CLIENT_ID", "OPENAI_CLIENT_SECRET"]


###############################################################################
[bfcl]
container = "nvcr.io/nvidia/eval-factory/bfcl:25.11"
# container-digest:sha256:79038a60e720557a403aad772943c4a03ffb4ffbd9406afd8ab6a5a190ffc4e3

[bfcl.tasks.chat.bfclv2_ast_prompting]
required_env_vars = []

[bfcl.tasks.chat.bfclv3_ast_prompting]
required_env_vars = []


###############################################################################
[profbench]
container = "nvcr.io/nvidia/eval-factory/profbench:25.11"
# container-digest:sha256:7e07d7758c55aaf9a341941b3eb1e5b37d50ee48a710af58916c35597de15256

[profbench.tasks.chat.llm_judge]
required_env_vars = []

[profbench.tasks.chat.report_generation]
required_env_vars = []


###############################################################################
[vlmevalkit]
container = "nvcr.io/nvidia/eval-factory/vlmevalkit:25.11"
# container-digest:sha256:ef22dbb3056032735b3e9f31d5c6c28e2af6e5b12b00fff3f5934345c60be17f

[vlmevalkit.tasks.vlm.ocrbench]
required_env_vars = []

[vlmevalkit.tasks.vlm.slidevqa]
required_env_vars = ["OPENAI_CLIENT_ID", "OPENAI_CLIENT_SECRET"]

[vlmevalkit.tasks.vlm.chartqa]
required_env_vars = []

[vlmevalkit.tasks.vlm.ai2d_judge]
required_env_vars = ["OPENAI_CLIENT_ID", "OPENAI_CLIENT_SECRET"]


###############################################################################
[garak]
container = "nvcr.io/nvidia/eval-factory/garak:25.11"
# container-digest:sha256:b2f476c52cc3e188f4317dc6da380269d74ede895d86dd6a3e60bb78a3fbfb12

[garak.tasks.chat.garak]
required_env_vars = []

###############################################################################
# NOTE(wprazuch): to verify if the tasks need any env var setting
[nemo_skills]
container = "nvcr.io/nvidia/eval-factory/nemo_skills:25.11"
# container-digest:sha256:f8269f1c6662017e60dd116b9f462db98349d9715214d6d6055fffd2ab12978d

[nemo_skills.tasks.chat.ns_aime2024]


[nemo_skills.tasks.chat.ns_aime2025]


[nemo_skills.tasks.chat.ns_bfcl_v3]
required_env_vars = []

[nemo_skills.tasks.chat.ns_bfcl_v4]
required_env_vars = []

[nemo_skills.tasks.chat.ns_gpqa]
required_env_vars = ["HF_TOKEN"]

[nemo_skills.tasks.chat.ns_ifbench]
required_env_vars = []

[nemo_skills.tasks.chat.ns_hle]
required_env_vars = []

[nemo_skills.tasks.chat.ns_livecodebench]
required_env_vars = []

[nemo_skills.tasks.chat.ns_mmlu]
required_env_vars = ["HF_TOKEN"]

[nemo_skills.tasks.chat.ns_mmlu_pro]
required_env_vars = ["HF_TOKEN"]

[nemo_skills.tasks.chat.ns_scicode]
required_env_vars = ["HF_TOKEN"]

[nemo_skills.tasks.chat.ns_aa_lcr]
required_env_vars = ["JUDGE_API_KEY"]

###############################################################################
[safety-harness]
container = "nvcr.io/nvidia/eval-factory/safety-harness:25.11"
# container-digest:sha256:5e2eec51a9ef5c8900849197956c0cbf547fc177f3aa64dacc4373d9fc541a06

[safety-harness.tasks.chat.aegis_v2]
required_env_vars = ["HF_TOKEN"]


###############################################################################
# NOTE(agronskiy): checked parity
[helm]
container = "nvcr.io/nvidia/eval-factory/helm:25.11"
# container-digest:sha256:a07bcdf0e6436cd7c4d4cd8591827a669c8e223da60dbce35d4eee3fdbcc73bd

[helm.tasks.chat.medcalc_bench]

[helm.tasks.chat.medec]

[helm.tasks.chat.head_qa]

[helm.tasks.chat.medbullets]

[helm.tasks.chat.pubmed_qa]

[helm.tasks.chat.ehr_sql]

[helm.tasks.chat.race_based_med]

[helm.tasks.chat.medhallu]

[helm.tasks.chat.mtsamples_replicate]

[helm.tasks.chat.aci_bench]

[helm.tasks.chat.mtsamples_procedures]

[helm.tasks.chat.medication_qa]

[helm.tasks.chat.med_dialog_healthcaremagic]

[helm.tasks.chat.med_dialog_icliniq]

[helm.tasks.chat.medi_qa]


###############################################################################
# NOTE(agronskiy): checked parity
[tooltalk]
container = "nvcr.io/nvidia/eval-factory/tooltalk:25.11"
# container-digest:sha256:008c039d34e6e9efebdca52efa3ff1b484a4c88da526b855a0c0773eaf2ba7d0

[tooltalk.tasks.chat.tooltalk]
