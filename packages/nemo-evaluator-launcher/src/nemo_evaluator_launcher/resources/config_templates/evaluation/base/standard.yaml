# Standard LLM Benchmarks for base models (completions endpoint, log-probability based)
# These tasks use log-probabilities to assess model confidence on answer choices
evaluation:
  tasks:
    - name: lm-evaluation-harness.mmlu # Log-prob based multiple choice
    - name: lm-evaluation-harness.gpqa # Log-prob based (completions version)
    - name: lm-evaluation-harness.arc_challenge # Log-prob based
    - name: lm-evaluation-harness.hellaswag # Log-prob based
    - name: lm-evaluation-harness.commonsense_qa # Log-prob based
