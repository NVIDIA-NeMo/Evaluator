{
  "filename": "nemo-fw/evaluation-doc.md",
  "lineno": 154,
  "status": "broken",
  "code": 0,
  "uri": "https://github.com/NVIDIA-NeMo/Evaluator/blob/main/scripts/evaluation_with_nemo_run.py#L267",
  "info": "Anchor 'L267' not found"
}
{
  "filename": "nemo-fw/evaluation-hf.md",
  "lineno": 26,
  "status": "broken",
  "code": 0,
  "uri": "https://github.com/NVIDIA-NeMo/Export-Deploy?tab=readme-ov-file#install-tensorrt-llm-vllm-or-trt-onnx-backend:~:text=cd%20/opt/Export%2DDeploy%0Auv%20sync%20%2D%2Dinexact%20%2D%2Dlink%2Dmode%20symlink%20%2D%2Dlocked%20%2D%2Dextra%20vllm%20%24(cat%20/opt/uv_args.txt)",
  "info": "Anchor 'install-tensorrt-llm-vllm-or-trt-onnx-backend%3A~%3Atext%3Dcd%20/opt/Export-Deploy%0Auv%20sync%20--inexact%20--link-mode%20symlink%20--locked%20--extra%20vllm%20%24%28cat%20/opt/uv_args.txt%29' not found"
}
{
  "filename": "nemo-fw/evaluation-hf.md",
  "lineno": 33,
  "status": "broken",
  "code": 0,
  "uri": "https://github.com/NVIDIA-NeMo/Export-Deploy?tab=readme-ov-file#install-tensorrt-llm-vllm-or-trt-onnx-backend:~:text=Install%20TransformerEngine%20%2B%20vLLM",
  "info": "Anchor 'install-tensorrt-llm-vllm-or-trt-onnx-backend%3A~%3Atext%3DInstall%20TransformerEngine%20%2B%20vLLM' not found"
}
{
  "filename": "deployment/bring-your-own-endpoint/hosted-services.md",
  "lineno": 158,
  "status": "broken",
  "code": 0,
  "uri": "https://platform.openai.com/docs/models",
  "info": "403 Client Error: Forbidden for url: https://platform.openai.com/docs/models"
}
{
  "filename": "nemo-fw/evaluation-doc.md",
  "lineno": 154,
  "status": "broken",
  "code": 0,
  "uri": "https://github.com/NVIDIA-NeMo/Evaluator/blob/main/scripts/evaluation_with_nemo_run.py#L232",
  "info": "Anchor 'L232' not found"
}

